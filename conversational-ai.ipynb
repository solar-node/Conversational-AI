{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36cdae03-05ec-48a3-948d-4a345eebdd92",
   "metadata": {},
   "source": [
    "# Conversational-AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78e62f99-437a-48a7-b029-cd3848782627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c44f77c2-299d-4cd4-87d2-1c4189ede5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "\n",
    "load_dotenv()\n",
    "os.environ['GOOGLE_API_KEY'] = os.getenv('GOOGLE_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16ac7356-11f0-49e8-a694-2266e49eabcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini = ChatGoogleGenerativeAI(\n",
    "    model = \"gemini-2.5-flash\",\n",
    "    temperature = 0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "538602e1-ccf6-481a-8d64-d7180fa5cf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a helpful assistant\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a4e2a37-e359-401d-bc8a-71f8a11cbcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    \n",
    "    messages = [\n",
    "        SystemMessage(content=system_message)\n",
    "    ]\n",
    "    \n",
    "    # history is  a list of dicts(role/content)\n",
    "    for turn in history:\n",
    "        if turn[\"role\"] == \"user\":\n",
    "            messages.append(HumanMessage(content=turn[\"content\"]))\n",
    "        elif turn[\"role\"] == \"assistant\":\n",
    "            messages.append(AIMessage(content=turn[\"content\"]))\n",
    "\n",
    "    messages.append(HumanMessage(content = message))\n",
    "\n",
    "    print(\"The history is: \")\n",
    "    print(history)\n",
    "    print(\"Message is: \")\n",
    "    print(messages)\n",
    "\n",
    "    # Streaming the results\n",
    "    response = \"\"\n",
    "\n",
    "    for chunk in gemini.stream(messages):\n",
    "        response += chunk.content\n",
    "        yield response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f40ddca-7a1b-443f-b0a4-5f9be36030dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "\n",
      "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/28 12:10:14 [W] [service.go:132] login to server failed: i/o deadline reached\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Using Gradio for making the chat interface\n",
    "chat_interface = gr.ChatInterface(\n",
    "    fn = chat,\n",
    "    type = \"messages\",\n",
    "    title = \"Conversational Chatbot\"\n",
    ")\n",
    "\n",
    "chat_interface.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37c71ff9-0d51-4380-86a5-3ff996ec2767",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"You are a senior ML researcher mentoring a student.\n",
    "Always explain concepts step by step with examples, \n",
    "and then ask a follow-up question to test their understanding. \n",
    "\n",
    "Always explain concepts using analogies from everyday life. \n",
    "Format the response with bullet points and short paragraphs. \n",
    "End with one motivating sentence.\n",
    "\n",
    "Whenever you explain something, first give a 3-sentence summary, \n",
    "then a detailed explanation, then provide a quick 2-question quiz at the end.\n",
    "\n",
    "You are an AI tutor. Every time you explain, \n",
    "link it to how it applies in Machine Learning or Data Science. \n",
    "Whenever possible, cite a real-world example.\n",
    "\n",
    "Before answering, always ask me one clarifying question. \n",
    "After explaining, suggest a related topic I should study next.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d04c41ad-bd60-4bbb-8a3f-95bb002e1ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    \n",
    "    messages = [\n",
    "        SystemMessage(content=system_message)\n",
    "    ]\n",
    "    \n",
    "    # history is  a list of dicts(role/content)\n",
    "    for turn in history:\n",
    "        if turn[\"role\"] == \"user\":\n",
    "            messages.append(HumanMessage(content=turn[\"content\"]))\n",
    "        elif turn[\"role\"] == \"assistant\":\n",
    "            messages.append(AIMessage(content=turn[\"content\"]))\n",
    "\n",
    "    messages.append(HumanMessage(content = message))\n",
    "\n",
    "    print(\"The history is: \")\n",
    "    print(history)\n",
    "    print(\"Message is: \")\n",
    "    print(messages)\n",
    "\n",
    "    # Streaming the results\n",
    "    response = \"\"\n",
    "\n",
    "    for chunk in gemini.stream(messages):\n",
    "        response += chunk.content\n",
    "        yield response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20cad8d4-5335-4e36-b6a6-c9532bd14bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7864\n",
      "\n",
      "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/28 12:21:55 [W] [service.go:132] login to server failed: i/o deadline reached\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history is: \n",
      "[]\n",
      "Message is: \n",
      "[SystemMessage(content='You are a senior ML researcher mentoring a student.\\nAlways explain concepts step by step with examples, \\nand then ask a follow-up question to test their understanding. \\n\\nAlways explain concepts using analogies from everyday life. \\nFormat the response with bullet points and short paragraphs. \\nEnd with one motivating sentence.\\n\\nWhenever you explain something, first give a 3-sentence summary, \\nthen a detailed explanation, then provide a quick 2-question quiz at the end.\\n\\nYou are an AI tutor. Every time you explain, \\nlink it to how it applies in Machine Learning or Data Science. \\nWhenever possible, cite a real-world example.\\n\\nBefore answering, always ask me one clarifying question. \\nAfter explaining, suggest a related topic I should study next.', additional_kwargs={}, response_metadata={}), HumanMessage(content='What can you do?', additional_kwargs={}, response_metadata={})]\n",
      "The history is: \n",
      "[{'role': 'user', 'metadata': None, 'content': 'What can you do?', 'options': None}, {'role': 'assistant', 'metadata': None, 'content': \"That's a great question! To make sure I give you the most relevant information, are you interested in my general capabilities as an AI, or specifically how I can assist you as a tutor in Machine Learning and Data Science?\", 'options': None}]\n",
      "Message is: \n",
      "[SystemMessage(content='You are a senior ML researcher mentoring a student.\\nAlways explain concepts step by step with examples, \\nand then ask a follow-up question to test their understanding. \\n\\nAlways explain concepts using analogies from everyday life. \\nFormat the response with bullet points and short paragraphs. \\nEnd with one motivating sentence.\\n\\nWhenever you explain something, first give a 3-sentence summary, \\nthen a detailed explanation, then provide a quick 2-question quiz at the end.\\n\\nYou are an AI tutor. Every time you explain, \\nlink it to how it applies in Machine Learning or Data Science. \\nWhenever possible, cite a real-world example.\\n\\nBefore answering, always ask me one clarifying question. \\nAfter explaining, suggest a related topic I should study next.', additional_kwargs={}, response_metadata={}), HumanMessage(content='What can you do?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"That's a great question! To make sure I give you the most relevant information, are you interested in my general capabilities as an AI, or specifically how I can assist you as a tutor in Machine Learning and Data Science?\", additional_kwargs={}, response_metadata={}), HumanMessage(content='how can i start my ML journey', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "## Using Gradio for making the chat interface\n",
    "chat_interface = gr.ChatInterface(\n",
    "    fn = chat,\n",
    "    type = \"messages\",\n",
    "    title = \"Conversational Chatbot\"\n",
    ")\n",
    "\n",
    "chat_interface.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
